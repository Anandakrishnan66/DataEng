{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8448fc1-d6f8-4f63-9143-bb58305225ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-639816121734102>:8\u001b[0m\n",
       "\u001b[1;32m      5\u001b[0m cosmos_database_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirbnb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m      6\u001b[0m cosmos_container_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgitcontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[0;32m----> 8\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n",
       "\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosmosDBIntegration\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n",
       "\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_endpoint) \\\n",
       "\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_master_key) \\\n",
       "\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
       "\u001b[1;32m     14\u001b[0m read_config \u001b[38;5;241m=\u001b[39m {\n",
       "\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n",
       "\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.read.customQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM c\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m     20\u001b[0m }\n",
       "\u001b[1;32m     22\u001b[0m write_config \u001b[38;5;241m=\u001b[39m {\n",
       "\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n",
       "\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n",
       "\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.database\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_database_name,\n",
       "\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.container\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_container_name\n",
       "\u001b[1;32m     27\u001b[0m }\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/sql/session.py:401\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n",
       "\u001b[1;32m    395\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n",
       "\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n",
       "\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# BEGIN-EDGE\u001b[39;00m\n",
       "\u001b[1;32m    398\u001b[0m sc \u001b[38;5;241m=\u001b[39m (\n",
       "\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\n",
       "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    402\u001b[0m )\n",
       "\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n",
       "\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n",
       "\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n",
       "\u001b[1;32m    406\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:555\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n",
       "\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n",
       "\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
       "\u001b[0;32m--> 555\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:204\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
       "\u001b[1;32m    202\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n",
       "\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
       "\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n",
       "\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:276\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
       "\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Check that we have at least the required parameters\u001b[39;00m\n",
       "\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.master\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
       "\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA master URL must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.app.name\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
       "\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn application name must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\n",
       "\u001b[0;31mRuntimeError\u001b[0m: A master URL must be set in your configuration"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\nFile \u001b[0;32m<command-639816121734102>:8\u001b[0m\n\u001b[1;32m      5\u001b[0m cosmos_database_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirbnb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m cosmos_container_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgitcontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosmosDBIntegration\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_endpoint) \\\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_master_key) \\\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m     14\u001b[0m read_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.read.customQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM c\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     22\u001b[0m write_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.database\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_database_name,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.container\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_container_name\n\u001b[1;32m     27\u001b[0m }\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/sql/session.py:401\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# BEGIN-EDGE\u001b[39;00m\n\u001b[1;32m    398\u001b[0m sc \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:555\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:204\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    202\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:276\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Check that we have at least the required parameters\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.master\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA master URL must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.app.name\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn application name must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mRuntimeError\u001b[0m: A master URL must be set in your configuration",
       "errorSummary": "<span class='ansi-red-fg'>RuntimeError</span>: A master URL must be set in your configuration",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "cosmos_endpoint = \n",
    "cosmos_master_key = \"\n",
    "cosmos_database_name = \"Airbnb\"\n",
    "cosmos_container_name = \"gitcontainer\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CosmosDBIntegration\") \\\n",
    "    .config(\"spark.cosmos.accountEndpoint\", cosmos_endpoint) \\\n",
    "    .config(\"spark.cosmos.accountKey\", cosmos_master_key) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "read_config = {\n",
    "    \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "    \"spark.cosmos.accountKey\": cosmos_master_key,\n",
    "    \"spark.cosmos.database\": cosmos_database_name,\n",
    "    \"spark.cosmos.container\": cosmos_container_name,\n",
    "    \"spark.cosmos.read.customQuery\": \"SELECT * FROM c\"\n",
    "}\n",
    "\n",
    "write_config = {\n",
    "    \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "    \"spark.cosmos.accountKey\": cosmos_master_key,\n",
    "    \"spark.cosmos.database\": cosmos_database_name,\n",
    "    \"spark.cosmos.container\": cosmos_container_name\n",
    "}\n",
    "\n",
    "df_listing_1 = spark.read.format(\"cosmos.oltp\").options(**read_config).load()\n",
    "df_listing_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e5f8605-de7a-44d6-a0bf-7a676d28ae9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize Spark Session (if not already initialized)\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# # Path to the Parquet file or directory you want to remove\n",
    "# path_to_remove = \"\"\n",
    "\n",
    "# # Remove the Parquet file or directory\n",
    "# dbutils.fs.rm(path_to_remove, True)\n",
    "\n",
    "# # Stop the Spark session (if needed)\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c46e251-0607-40f9-a0e8-111185eb7d6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-639816121734103>:8\u001b[0m\n",
       "\u001b[1;32m      5\u001b[0m cosmos_database_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirbnb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m      6\u001b[0m cosmos_container_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlakecontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[0;32m----> 8\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n",
       "\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosmosDBIntegration\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n",
       "\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_endpoint) \\\n",
       "\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_master_key) \\\n",
       "\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
       "\u001b[1;32m     14\u001b[0m read_config \u001b[38;5;241m=\u001b[39m {\n",
       "\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n",
       "\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.read.customQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM c\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m     20\u001b[0m }\n",
       "\u001b[1;32m     22\u001b[0m write_config \u001b[38;5;241m=\u001b[39m {\n",
       "\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n",
       "\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n",
       "\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.database\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_database_name,\n",
       "\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.container\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_container_name\n",
       "\u001b[1;32m     27\u001b[0m }\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/sql/session.py:401\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n",
       "\u001b[1;32m    395\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n",
       "\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n",
       "\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# BEGIN-EDGE\u001b[39;00m\n",
       "\u001b[1;32m    398\u001b[0m sc \u001b[38;5;241m=\u001b[39m (\n",
       "\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\n",
       "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    402\u001b[0m )\n",
       "\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n",
       "\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n",
       "\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n",
       "\u001b[1;32m    406\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:555\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n",
       "\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n",
       "\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
       "\u001b[0;32m--> 555\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:204\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
       "\u001b[1;32m    202\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n",
       "\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
       "\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n",
       "\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:276\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
       "\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Check that we have at least the required parameters\u001b[39;00m\n",
       "\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.master\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
       "\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA master URL must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.app.name\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
       "\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn application name must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\n",
       "\u001b[0;31mRuntimeError\u001b[0m: A master URL must be set in your configuration"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\nFile \u001b[0;32m<command-639816121734103>:8\u001b[0m\n\u001b[1;32m      5\u001b[0m cosmos_database_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirbnb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m cosmos_container_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlakecontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosmosDBIntegration\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_endpoint) \\\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_master_key) \\\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m     14\u001b[0m read_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.read.customQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM c\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     22\u001b[0m write_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.database\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_database_name,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.container\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_container_name\n\u001b[1;32m     27\u001b[0m }\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/sql/session.py:401\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# BEGIN-EDGE\u001b[39;00m\n\u001b[1;32m    398\u001b[0m sc \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:555\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:204\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    202\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:276\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Check that we have at least the required parameters\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.master\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA master URL must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.app.name\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn application name must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mRuntimeError\u001b[0m: A master URL must be set in your configuration",
       "errorSummary": "<span class='ansi-red-fg'>RuntimeError</span>: A master URL must be set in your configuration",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "cosmos_endpoint = \n",
    "cosmos_master_key = \"\n",
    "cosmos_database_name = \"Airbnb\"\n",
    "cosmos_container_name = \"lakecontainer\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CosmosDBIntegration\") \\\n",
    "    .config(\"spark.cosmos.accountEndpoint\", cosmos_endpoint) \\\n",
    "    .config(\"spark.cosmos.accountKey\", cosmos_master_key) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "read_config = {\n",
    "    \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "    \"spark.cosmos.accountKey\": cosmos_master_key,\n",
    "    \"spark.cosmos.database\": cosmos_database_name,\n",
    "    \"spark.cosmos.container\": cosmos_container_name,\n",
    "    \"spark.cosmos.read.customQuery\": \"SELECT * FROM c\"\n",
    "}\n",
    "\n",
    "write_config = {\n",
    "    \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "    \"spark.cosmos.accountKey\": cosmos_master_key,\n",
    "    \"spark.cosmos.database\": cosmos_database_name,\n",
    "    \"spark.cosmos.container\": cosmos_container_name\n",
    "}\n",
    "\n",
    "df_listing_2 = spark.read.format(\"cosmos.oltp\").options(**read_config).load()\n",
    "df_listing_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21f81889-6366-4493-8445-6c30ea1ca7e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-639816121734104>:8\u001b[0m\n",
       "\u001b[1;32m      5\u001b[0m cosmos_database_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirbnb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m      6\u001b[0m cosmos_container_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlcontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[0;32m----> 8\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n",
       "\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosmosDBIntegration\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n",
       "\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_endpoint) \\\n",
       "\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_master_key) \\\n",
       "\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
       "\u001b[1;32m     14\u001b[0m read_config \u001b[38;5;241m=\u001b[39m {\n",
       "\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n",
       "\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.read.customQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM c\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m     20\u001b[0m }\n",
       "\u001b[1;32m     22\u001b[0m write_config \u001b[38;5;241m=\u001b[39m {\n",
       "\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n",
       "\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n",
       "\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.database\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_database_name,\n",
       "\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.container\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_container_name\n",
       "\u001b[1;32m     27\u001b[0m }\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/sql/session.py:401\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n",
       "\u001b[1;32m    395\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n",
       "\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n",
       "\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# BEGIN-EDGE\u001b[39;00m\n",
       "\u001b[1;32m    398\u001b[0m sc \u001b[38;5;241m=\u001b[39m (\n",
       "\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\n",
       "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    402\u001b[0m )\n",
       "\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n",
       "\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n",
       "\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n",
       "\u001b[1;32m    406\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:555\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n",
       "\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n",
       "\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
       "\u001b[0;32m--> 555\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:204\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
       "\u001b[1;32m    202\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n",
       "\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
       "\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n",
       "\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/context.py:276\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
       "\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Check that we have at least the required parameters\u001b[39;00m\n",
       "\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.master\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
       "\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA master URL must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.app.name\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
       "\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn application name must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\n",
       "\u001b[0;31mRuntimeError\u001b[0m: A master URL must be set in your configuration"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\nFile \u001b[0;32m<command-639816121734104>:8\u001b[0m\n\u001b[1;32m      5\u001b[0m cosmos_database_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirbnb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m cosmos_container_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlcontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosmosDBIntegration\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_endpoint) \\\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosmos_master_key) \\\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m     14\u001b[0m read_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.read.customQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM c\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     22\u001b[0m write_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_endpoint,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.accountKey\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_master_key,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.database\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_database_name,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.cosmos.container\u001b[39m\u001b[38;5;124m\"\u001b[39m: cosmos_container_name\n\u001b[1;32m     27\u001b[0m }\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/sql/session.py:401\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# BEGIN-EDGE\u001b[39;00m\n\u001b[1;32m    398\u001b[0m sc \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:555\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:204\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    202\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/context.py:276\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Check that we have at least the required parameters\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.master\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA master URL must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.app.name\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn application name must be set in your configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\n\u001b[0;31mRuntimeError\u001b[0m: A master URL must be set in your configuration",
       "errorSummary": "<span class='ansi-red-fg'>RuntimeError</span>: A master URL must be set in your configuration",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "cosmos_endpoint = \"\n",
    "cosmos_master_key = \"\n",
    "cosmos_database_name = \"Airbnb\"\n",
    "cosmos_container_name = \"sqlcontainer\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CosmosDBIntegration\") \\\n",
    "    .config(\"spark.cosmos.accountEndpoint\", cosmos_endpoint) \\\n",
    "    .config(\"spark.cosmos.accountKey\", cosmos_master_key) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "read_config = {\n",
    "    \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "    \"spark.cosmos.accountKey\": cosmos_master_key,\n",
    "    \"spark.cosmos.database\": cosmos_database_name,\n",
    "    \"spark.cosmos.container\": cosmos_container_name,\n",
    "    \"spark.cosmos.read.customQuery\": \"SELECT * FROM c\"\n",
    "}\n",
    "\n",
    "write_config = {\n",
    "    \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "    \"spark.cosmos.accountKey\": cosmos_master_key,\n",
    "    \"spark.cosmos.database\": cosmos_database_name,\n",
    "    \"spark.cosmos.container\": cosmos_container_name\n",
    "}\n",
    "\n",
    "df_review = spark.read.format(\"cosmos.oltp\").options(**read_config).load()\n",
    "df_review.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "803eb2c8-1719-4dd8-b459-19c93a388d5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-1908672152785655>:1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_review\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
       "\n",
       "\u001b[0;31mNameError\u001b[0m: name 'df_review' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nFile \u001b[0;32m<command-1908672152785655>:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_review\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mNameError\u001b[0m: name 'df_review' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'df_review' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598444b5-4f23-4945-b9c1-8af59cd3ff3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "383671db-17cf-4662-a0e9-87eda2d12dd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_listing_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a38966cd-4582-4f74-98e5-f6d8227cd225",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: DataFrame[bedrooms: string, instant_bookable: string, host_total_listing_count: string, city: string, name: string, room_type: string, latitude: string, property_type: string, price: string, host_has_profile_pic: string, host_acceptance_rate: void, host_identity_verified: string, longitude: string, hostid: string, review_scores_cleanliness: string, review_scores_communication: string, review_scores_value: string, id: string, review_scores_checkin: string, amenities: string, host_response_rate: void, $listingid: string, host_since: string, host_is_superhost: string, review_scores_accuracy: string, host_response_time: void, minimum_nights: string, district: void, neighbourhood: string, host_location: string, maximum_nights: string, review_scores_location: string, accomodates: string, review_scores_rating: string]"
     ]
    }
   ],
   "source": [
    "df_listing_1.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e207aa1-6482-4434-884d-31798dd65277",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: DataFrame[bedrooms: string, instant_bookable: string, city: string, name: string, room_type: string, latitude: string, listing_id: string, property_type: string, price: string, host_has_profile_pic: string, host_acceptance_rate: void, host_identity_verified: string, longitude: string, review_scores_cleanliness: string, review_scores_communication: string, review_scores_value: string, id: string, review_scores_checkin: string, host_id: string, amenities: string, host_response_rate: void, host_since: string, host_is_superhost: string, review_scores_accuracy: string, host_response_time: void, minimum_nights: string, district: void, neighbourhood: string, host_location: string, maximum_nights: string, host_total_listings_count: string, review_scores_location: string, accommodates: string, review_scores_rating: string]"
     ]
    }
   ],
   "source": [
    "df_listing_2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a6a97d6-d2fa-4a5e-b3c9-a05c2ef95793",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: DataFrame[review_id: string, listing_id: string, id: string, reviewer_id: string, date: string]"
     ]
    }
   ],
   "source": [
    "df_review.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ddde5a3-6ff1-40dd-b717-1014e0df0a13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "|bedrooms|instant_bookable|host_total_listing_count|city|name|room_type|latitude|property_type|price|host_has_profile_pic|host_identity_verified|longitude|hostid|review_scores_cleanliness|review_scores_communication|review_scores_value|                  id|review_scores_checkin|amenities|$listingid|host_since|host_is_superhost|review_scores_accuracy|minimum_nights|neighbourhood|host_location|maximum_nights|review_scores_location|accomodates|review_scores_rating|\n",
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|0b25a89b-2cc1-46c...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f8614118-9190-4c7...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f9c7592d-36d5-429...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|e8c28338-b3f1-49f...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|9732406e-9181-4e8...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|4b79186d-f6ff-4cc...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|85eca38c-8f2d-4ce...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|768a4df9-56cc-4fb...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|8edebfcf-8905-47b...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|dbb39deb-2d9a-44d...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|d77a84a0-2a92-4cc...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|5e0ab312-a8e9-4bd...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|9881d5ff-d845-4c3...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|d4155f9e-d3c6-4b4...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|68464e43-d96d-45c...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|4f17de07-fd2f-411...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|6f6bada3-29bb-442...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|717326b1-aece-473...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f17ba4b2-4a32-46b...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|65b35fb7-c96b-44e...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listing_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e580292b-e7b8-4b1b-bfd7-0d8dc3c5d46f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_review_par=df_review.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff8d243b-ef09-44be-84fd-0dff6f5c3e1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_review_par.write.mode(\"overwrite\").format(\"parquet\").save(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet/*parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "039379a4-4787-44b2-a1af-6e7c6a427cd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-639816121734111>:1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001b[0m, in \u001b[0;36m_wrap_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
       "\u001b[1;32m     46\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
       "\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m---> 48\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m     49\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog_success(\n",
       "\u001b[1;32m     50\u001b[0m         module_name, class_name, function_name, time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start, signature\n",
       "\u001b[1;32m     51\u001b[0m     )\n",
       "\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:533\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n",
       "\u001b[1;32m    522\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
       "\u001b[1;32m    523\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n",
       "\u001b[1;32m    524\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n",
       "\u001b[1;32m    525\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m    530\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n",
       "\u001b[1;32m    531\u001b[0m )\n",
       "\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n",
       "\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n",
       "\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
       "\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
       "\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n",
       "\u001b[1;32m    230\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
       "\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n",
       "\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n",
       "\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n",
       "\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
       "\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
       "\n",
       "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet/*parquet."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)\nFile \u001b[0;32m<command-639816121734111>:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001b[0m, in \u001b[0;36m_wrap_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog_success(\n\u001b[1;32m     50\u001b[0m         module_name, class_name, function_name, time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start, signature\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:533\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    522\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    524\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    525\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    531\u001b[0m )\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\nFile \u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\n\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet/*parquet.",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [PATH_NOT_FOUND] Path does not exist: dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet/*parquet.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.read.parquet(\"/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet/*parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78a4b360-1201-4a16-acaf-e84dcc690ed3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-639816121734113>:1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m re\u001b[38;5;241m=\u001b[39m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbfs:/dbfs/airbnb/airbnbparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001b[0m, in \u001b[0;36m_wrap_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
       "\u001b[1;32m     46\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
       "\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m---> 48\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m     49\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog_success(\n",
       "\u001b[1;32m     50\u001b[0m         module_name, class_name, function_name, time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start, signature\n",
       "\u001b[1;32m     51\u001b[0m     )\n",
       "\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:533\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n",
       "\u001b[1;32m    522\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
       "\u001b[1;32m    523\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n",
       "\u001b[1;32m    524\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n",
       "\u001b[1;32m    525\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m    530\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n",
       "\u001b[1;32m    531\u001b[0m )\n",
       "\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n",
       "\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n",
       "\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n",
       "\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
       "\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
       "\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
       "\n",
       "File \u001b[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n",
       "\u001b[1;32m    230\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
       "\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n",
       "\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n",
       "\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n",
       "\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
       "\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
       "\n",
       "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: dbfs:/dbfs/airbnb/airbnbparquet."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)\nFile \u001b[0;32m<command-639816121734113>:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m re\u001b[38;5;241m=\u001b[39m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbfs:/dbfs/airbnb/airbnbparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001b[0m, in \u001b[0;36m_wrap_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog_success(\n\u001b[1;32m     50\u001b[0m         module_name, class_name, function_name, time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start, signature\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:533\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    522\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    524\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    525\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    531\u001b[0m )\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\nFile \u001b[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n\nFile \u001b[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\n\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: dbfs:/dbfs/airbnb/airbnbparquet.",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [PATH_NOT_FOUND] Path does not exist: dbfs:/dbfs/airbnb/airbnbparquet.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "re=spark.read.parquet(\"dbfs:/dbfs/airbnb/airbnbparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02c456a2-8e1a-4960-9f5e-b4294a6e3444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[23]: [FileInfo(path='dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/Listing1-1.csv', name='Listing1-1.csv', size=158497169, modificationTime=1722317528000),\n",
      " FileInfo(path='dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/Listing1.csv', name='Listing1.csv', size=158497169, modificationTime=1722317073000),\n",
      " FileInfo(path='dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/sales_data_sample.csv', name='sales_data_sample.csv', size=527958, modificationTime=1721632671000)]"
     ]
    }
   ],
   "source": [
    "# List files in the directory\n",
    "dbutils.fs.ls(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb600945-d290-457e-926b-f9e7458acce6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+-----------+----------+\n",
      "|review_id|listing_id|                  id|reviewer_id|      date|\n",
      "+---------+----------+--------------------+-----------+----------+\n",
      "|528101222|  17043128|6071c03e-dd98-410...|  258941269|2019-09-12|\n",
      "|598380770|  16534974|57dc37bf-0014-43a...|   11889766|2020-01-27|\n",
      "|336483869|    922888|5ca842de-75fa-43a...|  169175102|2018-10-14|\n",
      "|225110110|  22515373|8f6fb5f5-c218-4c0...|  143058352|2018-01-05|\n",
      "| 97106754|   5639167|583dc7d5-3ac8-49a...|   35897405|2016-08-26|\n",
      "+---------+----------+--------------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_review_par.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb46fec-2a62-4700-ac24-364c4f8fda03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "review_parquet=spark.read.parquet(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/airbnbparquet/*parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd41d15-5d32-4fe5-b3c7-818c66f0f7ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-1908672152785653>:1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m \u001b[43mreview_parquet\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
       "\n",
       "\u001b[0;31mNameError\u001b[0m: name 'review_parquet' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nFile \u001b[0;32m<command-1908672152785653>:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreview_parquet\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n\n\u001b[0;31mNameError\u001b[0m: name 'review_parquet' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'review_parquet' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c5f625-9d35-42f2-8755-d57c9fafc22f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+-----------+----------+\n",
      "|review_id|listing_id|                  id|reviewer_id|      date|\n",
      "+---------+----------+--------------------+-----------+----------+\n",
      "|528101222|  17043128|6071c03e-dd98-410...|  258941269|2019-09-12|\n",
      "|598380770|  16534974|57dc37bf-0014-43a...|   11889766|2020-01-27|\n",
      "|336483869|    922888|5ca842de-75fa-43a...|  169175102|2018-10-14|\n",
      "|225110110|  22515373|8f6fb5f5-c218-4c0...|  143058352|2018-01-05|\n",
      "| 97106754|   5639167|583dc7d5-3ac8-49a...|   35897405|2016-08-26|\n",
      "|217704560|  11077928|11368184-0dc5-487...|   57088798|2017-12-10|\n",
      "|342537751|  22659178|56923d6d-4bd4-4c0...|  197026894|2018-10-28|\n",
      "| 70875175|    262254|3ae7500a-6641-447...|   19258194|2016-04-21|\n",
      "|423554391|   1936772|835a615b-bbe5-4ac...|   96316198|2019-03-14|\n",
      "|334532561|  16698710|db279f5d-0f5d-415...|  156381484|2018-10-09|\n",
      "|349049118|  16732761|2758f2ce-b7d6-464...|   48290948|2018-11-16|\n",
      "|138315827|  12747935|ad2d62bb-2026-48b...|   67823139|2017-03-19|\n",
      "|155147521|  10077605|40ef8e36-c5e6-471...|  127229157|2017-05-27|\n",
      "|720722377|  46870147|d7fa44f8-a5ca-461...|  210552072|2021-01-02|\n",
      "|612843813|  16496389|f9b97a30-254f-4f2...|   63884093|2020-03-01|\n",
      "|702075423|  38538740|324c41af-77b5-474...|  128172488|2020-10-19|\n",
      "|435770282|  29211326|71b5158e-da85-46c...|   40909726|2019-04-11|\n",
      "|114998332|   8640907|2233d708-8493-43e...|    7052106|2016-11-21|\n",
      "|403310471|  27589169|cbb8027b-882d-461...|  190461918|2019-01-20|\n",
      "|224168025|  18669867|578afa4e-a6db-4fa...|  161336796|2018-01-02|\n",
      "+---------+----------+--------------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffa60c4a-f64b-4193-912b-c7a032e8eb87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_1_par=df_listing_1.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c32b2d-d12c-443a-a2d7-4d331d25625a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|host_acceptance_rate|\n",
      "+--------------------+\n",
      "|                null|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_listing_1_par.select(\"host_acceptance_rate\").distinct().show()\n",
    "df_listing_1_par=df_listing_1_par.drop(\"host_acceptance_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abe896bd-a863-4e2d-8ec6-a557e0274c23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_2_par=df_listing_2_par.drop(\"host_acceptance_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3462708-1137-44ff-8676-356e362f886a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[46]: ['bedrooms',\n",
      " 'instant_bookable',\n",
      " 'host_total_listing_count',\n",
      " 'city',\n",
      " 'name',\n",
      " 'room_type',\n",
      " 'latitude',\n",
      " 'property_type',\n",
      " 'price',\n",
      " 'host_has_profile_pic',\n",
      " 'host_identity_verified',\n",
      " 'longitude',\n",
      " 'hostid',\n",
      " 'review_scores_cleanliness',\n",
      " 'review_scores_communication',\n",
      " 'review_scores_value',\n",
      " 'id',\n",
      " 'review_scores_checkin',\n",
      " 'amenities',\n",
      " 'host_response_rate',\n",
      " '$listingid',\n",
      " 'host_since',\n",
      " 'host_is_superhost',\n",
      " 'review_scores_accuracy',\n",
      " 'host_response_time',\n",
      " 'minimum_nights',\n",
      " 'district',\n",
      " 'neighbourhood',\n",
      " 'host_location',\n",
      " 'maximum_nights',\n",
      " 'review_scores_location',\n",
      " 'accomodates',\n",
      " 'review_scores_rating']"
     ]
    }
   ],
   "source": [
    "df_listing_1_par.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525ed38b-f097-4da4-9d37-f6a7f258c838",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_2_par=df_listing_2.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8a7bcfe-f5b9-44a0-8531-17be10b271c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_2_par=df_listing_2_par.drop(\"host_acceptance_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "147fd239-0161-4985-8616-66ed2467d37e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|host_acceptance_rate|\n",
      "+--------------------+\n",
      "|                null|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_listing_2_par.select(\"host_acceptance_rate\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51215d00-43de-441f-a8e9-085198e65854",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_1_par=df_listing_1_par.drop(\"host_response_rate\")\n",
    "df_listing_2_par=df_listing_2_par.drop(\"host_response_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6c0e95f-b286-4005-8c8f-59b912f70916",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_1_par=df_listing_1_par.drop(\"host_response_time\")\n",
    "df_listing_2_par=df_listing_2_par.drop(\"host_response_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2a8cc6f-04c3-4d77-a055-0c79be7f5f12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_1_par=df_listing_1_par.drop(\"district\")\n",
    "df_listing_2_par=df_listing_2_par.drop(\"district\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95845a88-4f11-41af-8f70-6c0b2b1d4428",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_1_par.write.mode(\"overwrite\").format(\"parquet\").save(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/listing_1parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5caf5ae0-ebd0-4d2d-8c9c-d3a101a3d582",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_listing_2_par.write.mode(\"overwrite\").format(\"parquet\").save(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/listing_2parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "767e3685-edf7-4b6d-81eb-137ceaa2e5b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "re=spark.read.parquet(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/listing_2parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763d4658-d3b9-4d21-b312-a630f442ed41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+--------------+--------------------+------------+---------+----------+----------------+-----+--------------------+----------------------+---------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+--------------------+----------+-----------------+----------------------+--------------+-------------------+--------------------+--------------+-------------------------+----------------------+------------+--------------------+\n",
      "|bedrooms|instant_bookable|          city|                name|   room_type| latitude|listing_id|   property_type|price|host_has_profile_pic|host_identity_verified|longitude|review_scores_cleanliness|review_scores_communication|review_scores_value|                  id|review_scores_checkin|  host_id|           amenities|host_since|host_is_superhost|review_scores_accuracy|minimum_nights|      neighbourhood|       host_location|maximum_nights|host_total_listings_count|review_scores_location|accommodates|review_scores_rating|\n",
      "+--------+----------------+--------------+--------------------+------------+---------+----------+----------------+-----+--------------------+----------------------+---------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+--------------------+----------+-----------------+----------------------+--------------+-------------------+--------------------+--------------+-------------------------+----------------------+------------+--------------------+\n",
      "|       3|               f|Rio de Janeiro|Ape pra ir a pe p...|Entire place|-22.97228|   7802427|Entire apartment|  450|                   t|                     t|-43.39934|                        9|                          9|                  9|f4d75f6b-501f-422...|                    9| 26603511|['Elevator', 'Kit...|23-01-2015|                f|                     9|             3|        Jacarepagua|Rio de Janeiro, S...|          1125|                        1|                     9|           7|                  87|\n",
      "|       2|               f|       Bangkok|Bangna...|Entire place|  13.6725|  43384452|Entire apartment|  560|                   t|                     t|100.60665|                     null|                       null|               null|48949cf5-f682-42a...|                 null|343049020|['Air conditionin...|03-04-2020|                f|                  null|             7|            Bang Na|                  CN|          1125|                        1|                  null|           4|                null|\n",
      "|    null|               f|      New York|Cozy, clean studi...|Entire place| 40.81882|   7305718|Entire apartment|  150|                   t|                     t|  -73.956|                     null|                       null|               null|35b965cf-808c-41f...|                 null| 38269863|['Smoke alarm', '...|12-07-2015|                f|                  null|            30|             Harlem|San Francisco, Ca...|          1125|                        1|                  null|           3|                null|\n",
      "|       1|               f|        Sydney|Glebe one bedroom...|Entire place|-33.87879|   8954340|Entire apartment|   60|                   t|                     t|151.18359|                     null|                       null|               null|5314be60-ae07-409...|                 null| 43842582|['Long term stays...|10-09-2015|                f|                  null|             1|             Sydney|Sydney, New South...|          1125|                        1|                  null|           2|                null|\n",
      "|    null|               f|        Sydney|chasesuites/chats...|Entire place| -33.7958|  46306273|Entire apartment|   95|                   t|                     t|151.18482|                     null|                       null|               null|98207158-8403-41a...|                 null|374838429|['Washer', 'Iron'...|08-11-2020|                f|                  null|             2|         Willoughby|                  AU|          1125|                        1|                  null|           2|                null|\n",
      "|       1|               f|      New York|STUNNING, HUGE 1 ...|Entire place| 40.84409|  20928494|Entire apartment|  105|                   t|                     t|-73.94236|                       10|                         10|                 10|b4dbfcd0-3718-476...|                   10| 22721010|['Lockbox', 'Hair...|19-10-2014|                f|                    10|            30| Washington Heights|New York, New Yor...|          1125|                        1|                     9|           4|                  97|\n",
      "|    null|               f|         Paris|Magnifique 40m ...|Entire place| 48.88288|  21499168|Entire apartment|   73|                   t|                     t|  2.31714|                        9|                         10|                  9|f32d6ee8-f338-4b5...|                    9| 25943364|['Heating', 'Iron...|11-01-2015|                f|                    10|             1|Batignolles-Monceau|Paris, Ile-de-Fra...|          1125|                        1|                     9|           4|                  88|\n",
      "|       1|               t|        Sydney|Great spot, close...|Entire place|-33.92276|  30697425|Entire apartment|  120|                   t|                     f|151.19832|                        9|                         10|                 10|f2091151-95dd-489...|                   10|229776518|['Washer', 'Iron'...|09-12-2018|                f|                    10|             4|         Botany Bay|                  AU|          1125|                        1|                     9|           2|                 100|\n",
      "|       2|               f|        Sydney|Modern Sun Filled...|Entire place|-33.83639|   9845127|Entire apartment|  114|                   t|                     f|151.21333|                        8|                          9|                  9|5556e309-e937-4db...|                    9| 50692816|['Washer', 'Free ...|06-12-2015|                f|                     9|             2|       North Sydney|           Singapore|          1125|                        1|                     9|           2|                  80|\n",
      "|       1|               f|      New York|Large Bright FULL...|Entire place| 40.69935|  22224790|Entire apartment|   95|                   t|                     t|-73.91287|                       10|                         10|                 10|a795923b-9df7-4de...|                   10|  1695734|['Breakfast', 'Ir...|03-02-2012|                f|                    10|            30|           Bushwick|New York, New Yor...|          1125|                        1|                    10|           4|                 100|\n",
      "|       2|               f|   Mexico City|Polanco - Accesib...|Entire place| 19.43907|   7646656|Entire apartment|  900|                   t|                     t|-99.19214|                       10|                         10|                 10|85489c9f-f5bb-41c...|                   10| 19117000|['TV', 'Dedicated...|29-07-2014|                t|                    10|             2|     Miguel Hidalgo|Mexico City, Fede...|          1125|                        1|                    10|           4|                  99|\n",
      "|       2|               f|         Paris|Beautiful bright ...|Entire place| 48.86357|  28266909|Entire apartment|  182|                   t|                     t|    2.348|                        9|                         10|                  9|21ae8bc1-e277-47f...|                    9|213484634|['Shampoo', 'Heat...|04-09-2018|                f|                     9|             1|             Louvre|Paris, Ile-de-Fra...|          1125|                        1|                    10|           6|                  89|\n",
      "|       1|               f|Rio de Janeiro|Copacabana Vista ...|Entire place|-22.96735|  32603631|Entire apartment|  140|                   t|                     t|-43.18205|                        9|                         10|                  9|61b2fe52-4c89-43e...|                   10|245072737|['Hangers', 'Elev...|24-02-2019|                f|                    10|             4|         Copacabana|Rio de Janeiro, S...|          1125|                        3|                    10|           4|                  90|\n",
      "|       3|               f|Rio de Janeiro|Apartamento vista...|Entire place|-23.00489|  28053950|Entire apartment|  490|                   t|                     f|-43.33037|                       10|                         10|                  9|e1f39156-d0cc-4cb...|                   10|211924644|['Coffee maker', ...|26-08-2018|                f|                    10|             3|    Barra da Tijuca|Rio de Janeiro, S...|          1125|                        1|                    10|           8|                 100|\n",
      "|       2|               f|      Istanbul|Perfectly Located...|Entire place|  41.0543|  35176503|Entire apartment|  300|                   t|                     t| 28.99936|                     null|                       null|               null|31e70bd5-e2ce-4c7...|                 null|  1660327|['Hangers', 'Firs...|27-01-2012|                f|                  null|             7|           Besiktas|Istanbul, Istanbu...|          1125|                        1|                  null|           4|                null|\n",
      "|       1|               f|     Hong Kong|Morden apartment~...|Entire place|  22.3072|  38837623|Entire apartment|  500|                   t|                     t|114.16764|                       10|                         10|                  6|3a7fc2ad-de60-4e5...|                   10|228380675|['Hair dryer', 'D...|30-11-2018|                f|                    10|             1|      Yau Tsim Mong|           Hong Kong|          1125|                        1|                    10|           2|                 100|\n",
      "|       1|               f|         Paris|Cosy apartment Mo...|Entire place| 48.89447|  19221925|Entire apartment|   40|                   t|                     t|  2.33721|                     null|                       null|               null|cf7e5a6d-412c-4e5...|                 null| 22037731|['Kitchen', 'Hair...|02-10-2014|                f|                  null|             1|  Buttes-Montmartre|Paris, Ile-de-Fra...|          1125|                        1|                  null|           2|                null|\n",
      "|       1|               f|         Paris|Luminous and quie...|Entire place| 48.83552|  14647669|Entire apartment|  110|                   t|                     f|  2.34768|                        9|                         10|                  9|e6c70889-e967-4ca...|                   10| 90946352|['Children\\u2019s...|20-08-2016|                f|                    10|             4|           Gobelins|Nice, Provence-Al...|          1125|                        2|                    10|           4|                  92|\n",
      "|       2|               f|Rio de Janeiro|Ap moderno perto ...|Entire place|-22.95085|  39410870|Entire apartment|  120|                   t|                     t|-43.19221|                       10|                         10|                  9|80f21949-6c3a-466...|                   10| 83937185|['Air conditionin...|15-07-2016|                f|                     9|             4|           Botafogo|Rio de Janeiro, S...|          1125|                        1|                    10|           4|                 100|\n",
      "|       1|               f|         Paris|Charmant 2P - P...|Entire place| 48.85756|  34085985|Entire apartment|   86|                   t|                     f|  2.39822|                        8|                         10|                 10|2999a935-8905-4c5...|                   10| 21932510|['Cooking basics'...|29-09-2014|                f|                    10|             6|       Menilmontant|Paris, Ile-de-Fra...|          1125|                        1|                    10|           2|                 100|\n",
      "+--------+----------------+--------------+--------------------+------------+---------+----------+----------------+-----+--------------------+----------------------+---------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+--------------------+----------+-----------------+----------------------+--------------+-------------------+--------------------+--------------+-------------------------+----------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "re.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70d7086b-06ca-4dd6-b94e-9f32ffd3aa2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "listing_1=spark.read.parquet(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/listing_1parquet/*parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efc8dbcf-67bc-4351-a23f-916a60c28065",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "|bedrooms|instant_bookable|host_total_listing_count|city|name|room_type|latitude|property_type|price|host_has_profile_pic|host_identity_verified|longitude|hostid|review_scores_cleanliness|review_scores_communication|review_scores_value|                  id|review_scores_checkin|amenities|$listingid|host_since|host_is_superhost|review_scores_accuracy|minimum_nights|neighbourhood|host_location|maximum_nights|review_scores_location|accomodates|review_scores_rating|\n",
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|0b25a89b-2cc1-46c...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f8614118-9190-4c7...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f9c7592d-36d5-429...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|e8c28338-b3f1-49f...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|9732406e-9181-4e8...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|4b79186d-f6ff-4cc...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|85eca38c-8f2d-4ce...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|768a4df9-56cc-4fb...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|8edebfcf-8905-47b...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|dbb39deb-2d9a-44d...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|d77a84a0-2a92-4cc...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|5e0ab312-a8e9-4bd...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|9881d5ff-d845-4c3...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|d4155f9e-d3c6-4b4...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|68464e43-d96d-45c...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|4f17de07-fd2f-411...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|6f6bada3-29bb-442...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|717326b1-aece-473...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f17ba4b2-4a32-46b...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|65b35fb7-c96b-44e...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listing_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc5d642-99fa-452e-b5b9-fbab38abaa27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "listing_2=spark.read.parquet(\"dbfs:/FileStore/shared_uploads/ananda33krishnan@outlook.com/listing_1parquet/*parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16a4b076-fa5f-4499-bb21-78eed8e2935b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "|bedrooms|instant_bookable|host_total_listing_count|city|name|room_type|latitude|property_type|price|host_has_profile_pic|host_identity_verified|longitude|hostid|review_scores_cleanliness|review_scores_communication|review_scores_value|                  id|review_scores_checkin|amenities|$listingid|host_since|host_is_superhost|review_scores_accuracy|minimum_nights|neighbourhood|host_location|maximum_nights|review_scores_location|accomodates|review_scores_rating|\n",
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|0b25a89b-2cc1-46c...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f8614118-9190-4c7...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f9c7592d-36d5-429...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|e8c28338-b3f1-49f...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|9732406e-9181-4e8...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|4b79186d-f6ff-4cc...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|85eca38c-8f2d-4ce...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|768a4df9-56cc-4fb...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|8edebfcf-8905-47b...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|dbb39deb-2d9a-44d...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|d77a84a0-2a92-4cc...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|5e0ab312-a8e9-4bd...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|9881d5ff-d845-4c3...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|d4155f9e-d3c6-4b4...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|68464e43-d96d-45c...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|4f17de07-fd2f-411...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|6f6bada3-29bb-442...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|717326b1-aece-473...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|f17ba4b2-4a32-46b...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "|    null|            null|                    null|null|null|     null|    null|         null| null|                null|                  null|     null|  null|                     null|                       null|               null|65b35fb7-c96b-44e...|                 null|     null|      null|      null|             null|                  null|          null|         null|         null|          null|                  null|       null|                null|\n",
      "+--------+----------------+------------------------+----+----+---------+--------+-------------+-----+--------------------+----------------------+---------+------+-------------------------+---------------------------+-------------------+--------------------+---------------------+---------+----------+----------+-----------------+----------------------+--------------+-------------+-------------+--------------+----------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listing_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26a9aa43-e8be-4e28-ab4c-60ad1d1bc79a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "listing_1.join(listing_2,(\"listing\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NotebookAirbnb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
